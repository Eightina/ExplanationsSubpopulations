{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "# string = '''python run.py --dataset {dataset} --blackbox_model {blackbox} --explanation_type {etype} --explanation_model {explanation} --n_features 10 --model_type JTT --evaluate_val --seed 1 --output_dir ./output/eff_{blackbox}_{explanation}_{dataset} '''\n",
    "# for blackbox in [\"lr\", \"xgb\", \"rf\", \"nn\", \"svm_rbf\", ]:\n",
    "#     # for explanation in [\"lime\", \"factor_gam\",  \"decision_tree\",\"shap_blackbox_preprocessed\"]:\n",
    "#     for explanation in [\"lime\", \"factor_gam\",  \"decision_tree\"]:\n",
    "#         for dataset in [\"adult_cleaned\", \"compas_balanced\", \"lsac\"]:\n",
    "#             if explanation == \"lime\" or explanation == \"shap_blackbox_preprocessed\":\n",
    "#                 etype = \"local\"\n",
    "#             else:\n",
    "#                 etype = \"global\"\n",
    "#             print(string.format(\\\n",
    "#                 dataset = dataset,\n",
    "#                 blackbox = blackbox,\n",
    "#                 etype = etype,\n",
    "#                 explanation = explanation\n",
    "#             ))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import hashlib\n",
    "import json\n",
    "from pathlib import Path\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_auc_score, auc, roc_curve\n",
    "from sklearn import metrics\n",
    "import warnings\n",
    "# NB: Warnings occur when computing metrics for groups with\n",
    "# low sample sizes. In our case, we don't use the metrics \n",
    "# for these groups.\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from compute_metrics import Model\n",
    "from lib.TabularDataset import dataset_params\n",
    "from lib import TabularDataset\n",
    "from result_latex_utils import agg_func\n",
    "# from result_latex_utils import meanPairDiff, agg_func, bold_max\n",
    "\n",
    "\n",
    "# res_dir = Path('/scratch/ssd001/home/aparna/explanations-subpopulations/output_main')\n",
    "# res_dir = Path('../output')\n",
    "res_dir = Path('../output_robust')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('../output_robust/eff_lr_lime_adult_cleaned/lr_local_lime.csv'),\n",
       " WindowsPath('../output_robust/robust_ijtt/lr_local_lime.csv'),\n",
       " WindowsPath('../output_robust/robust_jdro/lr_local_lime.csv'),\n",
       " WindowsPath('../output_robust/robust_jtt/lr_local_lime.csv')]"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retain column names\n",
    "retain_cols=False\n",
    "list(res_dir.glob('**/*.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_raw = []\n",
    "for path in res_dir.glob('**/*.csv'):\n",
    "    args = json.load((path.parent/'args.json').open('r'))\n",
    "    # all settings for paper table 1\n",
    "    #'lime','shap_blackbox_preprocessed',\n",
    "    # if args['model_type']!='JTT' and  args['explanation_type']=='local' and args['dataset'] in ['adult','compas_balanced','lsac','adult_cleaned','mimic_tab_robust','mimic_tab_fair_ds']:# and args['explanation_model'] in ['lime_test_new','lime_test','lime','shap_blackbox_preprocessed']:\n",
    "    if True:\n",
    "        hparams = [i for i in list(args.keys()) if i not in ['seed', 'output_dir']]\n",
    "        args['hparam_id'] = hashlib.md5(str([args[i] for i in hparams]).encode('utf-8')).hexdigest()\n",
    "        \n",
    "        \n",
    "        res = pd.read_csv(path)\n",
    "        \n",
    "        # get performance on test set\n",
    "        res = res[res.set=='test']\n",
    "\n",
    "        if res.shape[0]>0:\n",
    "            dataset = TabularDataset.Dataset(args['dataset'])\n",
    "            X_train, X_train_expl, X_val_expl, X_test, y_train, y_train_expl, y_val_expl, y_test, g_train, g_train_expl, g_val_expl, g_test = dataset.get_data(\n",
    "            retain_cols=retain_cols)\n",
    "            \n",
    "            # to check that the whole test set is present\n",
    "            assert res.shape[0]==g_test.shape[0]\n",
    "            res[dataset_params[args['dataset']].sensitive_attributes] = g_test.values\n",
    "            assert res[res['blackbox_prob'].isna()].shape[0]==0\n",
    "            assert res[res['expl_pred'].isna()].shape[0]==0\n",
    "                            \n",
    "            if sum(~np.isfinite(res['expl_pred'].values))>0:\n",
    "                raise ValueError('For dataset {}, model {}'.format(args['dataset'],\n",
    "                                                                  args['explanation_model']))\n",
    "                \n",
    "            # compute metrics over all items in test set\n",
    "            args['accuracy_all'] = ((res['expl_pred'].values >= 0.5) == res[\n",
    "                                          'blackbox_pred']).sum() / len(res)\n",
    "            fpr, tpr, thresholds = roc_curve(res['blackbox_pred'].values, res['expl_pred'].values\n",
    "                                             , pos_label=1)\n",
    "            roc = metrics.auc(fpr, tpr)\n",
    "            args['auroc_all'] = roc\n",
    "            args['prevalence_all']= res['blackbox_pred'].mean()\n",
    "\n",
    "            group_names = dataset_params[args['dataset']].sensitive_attributes\n",
    "            unique_groups = res[group_names].drop_duplicates()\n",
    "            for grp in group_names:\n",
    "                for val in res[grp].unique():\n",
    "                    unique_groups = unique_groups.append({grp: \n",
    "                                                          val, **{i: np.nan for i in group_names if i != grp}}, \n",
    "                                                         ignore_index = True)\n",
    "\n",
    "            for group in range(unique_groups.shape[0]):\n",
    "                group_i = unique_groups.iloc[group].values\n",
    "                \n",
    "                mask = ~pd.isnull(group_i)\n",
    "                curr_group_names = np.array(group_names)[mask]\n",
    "                curr_group_vals = group_i[mask]\n",
    "                sel_rows1 = res[(res[np.array(group_names)[mask]].values ==\n",
    "                       group_i[mask]).all(1)]\n",
    "                \n",
    "                # if we have 2 sensitive group columns\n",
    "                if len(curr_group_names)==2:\n",
    "                    sel_rows = res[(res[curr_group_names[0]]== curr_group_vals[0])&\n",
    "                                   (res[curr_group_names[1]]== curr_group_vals[1])]\n",
    "                elif len(curr_group_names)==1:\n",
    "                    sel_rows = res[res[curr_group_names[0]]== curr_group_vals[0]]\n",
    "                else:\n",
    "                    print('Warning: Default setting!')\n",
    "                    sel_rows = res\n",
    "                \n",
    "                # checking that logic of row selection works \n",
    "                assert sel_rows1.equals(sel_rows)\n",
    "                \n",
    "                # computing performance on given group\n",
    "                group_0_val_model = Model(sel_rows['expl_pred'].values, sel_rows[\n",
    "                                          'blackbox_pred'].values,\n",
    "                                         sel_rows[\n",
    "                                          'blackbox_prob'].values)\n",
    "                all_metrics = group_0_val_model.compute()\n",
    "                args_group = {\n",
    "                    **copy.deepcopy(args),\n",
    "                    **all_metrics\n",
    "                             }\n",
    "                # some metadata\n",
    "                args_group['group'] = str(unique_groups.iloc[group].values)\n",
    "                args_group['n'] = len(sel_rows)\n",
    "                args_group['level'] = mask.sum()\n",
    "                args_group['prevalence'] = sel_rows['blackbox_pred'].mean()\n",
    "                args_group['pred_prevalence'] = np.mean(sel_rows['expl_pred']>=0.5)\n",
    "                df_raw.append(args_group)\n",
    "                # print(args_group)\n",
    "\n",
    "df_local = pd.DataFrame(df_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_params[df_local['dataset'][0]].sensitive_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['dataset', 'blackbox_model', 'explanation_type', 'explanation_model',\n",
       "       'n_features', 'model_type', 'seed', 'experiment', 'output_dir',\n",
       "       'ignore_lime_weights', 'evaluate_val', 'max_epochs', 'perturb_sigma',\n",
       "       'balance_groups', 'balance_labels', 'balance_group_idx',\n",
       "       'train_grp_clf', 'grp_clf_attr', 'lr', 'C', 'batch_size', 'debug',\n",
       "       'jtt_lambda', 'jtt_thres', 'joint_dro_alpha', 'groupdro_eta',\n",
       "       'tree_depth', 'gam_max_iter', 'hparam_id', 'accuracy_all', 'auroc_all',\n",
       "       'prevalence_all', 'AUROC', 'ACC', 'epsilon', 'group', 'n', 'level',\n",
       "       'prevalence', 'pred_prevalence'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_local.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [1. 4.]\n",
       "1       [1. 2.]\n",
       "2       [0. 4.]\n",
       "3       [1. 1.]\n",
       "4       [0. 2.]\n",
       "        ...    \n",
       "63    [nan  4.]\n",
       "64    [nan  2.]\n",
       "65    [nan  1.]\n",
       "66    [nan  3.]\n",
       "67    [nan  0.]\n",
       "Name: group, Length: 68, dtype: object"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_local.group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['JTT', 'IJTT', 'JointDRO'], dtype=object)"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_local.model_type.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group settings\n",
    "list_groups = [\n",
    "    '[ 0. nan]',\n",
    "    '[ 1. nan]',\n",
    "    '[nan  0.]',\n",
    "    '[nan  1.]',\n",
    "    '[nan  2.]',\n",
    "    '[nan  3.]',\n",
    "    '[nan  4.]'\n",
    "    \n",
    "    \n",
    "]\n",
    "\n",
    "# the two sensitive groups of interest for all 4 datasets\n",
    "# NB: first item in tuple is sex, second is race\n",
    "# so here sex is considered the sensitive attribute for\n",
    "# Adult and MIMIC and race for COMPAS and LSAC\n",
    "list_groups_dict={}\n",
    "list_groups_dict['adult']=[\n",
    "    '[ 0. nan]',\n",
    "    '[ 1. nan]']\n",
    "list_groups_dict['adult_cleaned']=[\n",
    "    '[ 0. nan]',\n",
    "    '[ 1. nan]']\n",
    "list_groups_dict['mimic_tab_robust']=[\n",
    "     '[ 0. nan]',\n",
    "     '[ 1. nan]']\n",
    "\n",
    "list_groups_dict['lsac']=[\n",
    "    '[nan  0.]',\n",
    "    '[nan  1.]',\n",
    "    '[nan  2.]',\n",
    "    '[nan  3.]',\n",
    "    '[nan  4.]']\n",
    "list_groups_dict['lsac_cat']=[\n",
    "    '[nan  0.]',\n",
    "    '[nan  1.]',\n",
    "    '[nan  2.]',\n",
    "    '[nan  3.]',\n",
    "    '[nan  4.]']\n",
    "\n",
    "list_groups_dict['compas_balanced']=[\n",
    "    '[nan  0.]',\n",
    "    '[nan  1.]']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_alg = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetching hyperparams\n",
    "for path in res_dir.glob('**/*.csv'):\n",
    "    args = json.load((path.parent/'args.json').open('r'))\n",
    "    hparams = [i for i in list(args.keys()) if i not in  ['seed', 'output_dir']]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_gap_row(row, disp='auroc',kind='mean',return_type='str_sum',\n",
    "                    gap_or_not='_gap',\n",
    "                    list_groups=list_groups):\n",
    "    col_names = []\n",
    "    col_mean_names = []\n",
    "    for group in list_groups:\n",
    "        col_names.append(f'{disp}_{group}{gap_or_not}')\n",
    "        col_mean_names.append((f'{disp}_{group}{gap_or_not}',kind))\n",
    "    \n",
    "    if return_type=='str_sum':\n",
    "        max_val_ind = np.nanargmax(row[col_mean_names].values)\n",
    "        val=row[col_names[max_val_ind]]\n",
    "    elif return_type=='n':\n",
    "        max_val_ind = np.nanargmax(row[col_mean_names].values)\n",
    "        val= row[col_mean_names[max_val_ind]]\n",
    "    else:\n",
    "        max_val_ind = np.nanargmax(row[col_names].values)\n",
    "        val= row[col_names[max_val_ind]]\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "sens_feature_dict={}\n",
    "sens_feature_dict['adult_cleaned']='1'\n",
    "sens_feature_dict['lsac']='2'\n",
    "sens_feature_dict['mimic_tab_robust']='1'\n",
    "sens_feature_dict['compas_balanced']='2'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "# balance sensitive attribute groups by oversampling during training?\n",
    "balance_group_ind = False\n",
    "\n",
    "# balance labels by oversampling during training?\n",
    "# NB: We will always do this for LSAC, see Appendix\n",
    "# in paper\n",
    "balance_labels_ind = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>blackbox_model</th>\n",
       "      <th>explanation_type</th>\n",
       "      <th>explanation_model</th>\n",
       "      <th>n_features</th>\n",
       "      <th>model_type</th>\n",
       "      <th>seed</th>\n",
       "      <th>experiment</th>\n",
       "      <th>output_dir</th>\n",
       "      <th>ignore_lime_weights</th>\n",
       "      <th>...</th>\n",
       "      <th>auroc_all</th>\n",
       "      <th>prevalence_all</th>\n",
       "      <th>AUROC</th>\n",
       "      <th>ACC</th>\n",
       "      <th>epsilon</th>\n",
       "      <th>group</th>\n",
       "      <th>n</th>\n",
       "      <th>level</th>\n",
       "      <th>prevalence</th>\n",
       "      <th>pred_prevalence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>adult_cleaned</td>\n",
       "      <td>lr</td>\n",
       "      <td>local</td>\n",
       "      <td>lime</td>\n",
       "      <td>10</td>\n",
       "      <td>JTT</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>output\\eff_lr_lime_adult_cleaned</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.942752</td>\n",
       "      <td>0.188946</td>\n",
       "      <td>0.941252</td>\n",
       "      <td>0.783150</td>\n",
       "      <td>-0.082286</td>\n",
       "      <td>[1. 4.]</td>\n",
       "      <td>2813</td>\n",
       "      <td>2</td>\n",
       "      <td>0.257732</td>\n",
       "      <td>0.040882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>adult_cleaned</td>\n",
       "      <td>lr</td>\n",
       "      <td>local</td>\n",
       "      <td>lime</td>\n",
       "      <td>10</td>\n",
       "      <td>JTT</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>output\\eff_lr_lime_adult_cleaned</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.942752</td>\n",
       "      <td>0.188946</td>\n",
       "      <td>0.950840</td>\n",
       "      <td>0.879121</td>\n",
       "      <td>-0.179015</td>\n",
       "      <td>[1. 2.]</td>\n",
       "      <td>273</td>\n",
       "      <td>2</td>\n",
       "      <td>0.139194</td>\n",
       "      <td>0.025641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>adult_cleaned</td>\n",
       "      <td>lr</td>\n",
       "      <td>local</td>\n",
       "      <td>lime</td>\n",
       "      <td>10</td>\n",
       "      <td>JTT</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>output\\eff_lr_lime_adult_cleaned</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.942752</td>\n",
       "      <td>0.188946</td>\n",
       "      <td>0.957388</td>\n",
       "      <td>0.938636</td>\n",
       "      <td>-0.242103</td>\n",
       "      <td>[0. 4.]</td>\n",
       "      <td>1320</td>\n",
       "      <td>2</td>\n",
       "      <td>0.077273</td>\n",
       "      <td>0.015909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>adult_cleaned</td>\n",
       "      <td>lr</td>\n",
       "      <td>local</td>\n",
       "      <td>lime</td>\n",
       "      <td>10</td>\n",
       "      <td>JTT</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>output\\eff_lr_lime_adult_cleaned</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.942752</td>\n",
       "      <td>0.188946</td>\n",
       "      <td>0.896774</td>\n",
       "      <td>0.711340</td>\n",
       "      <td>-0.041104</td>\n",
       "      <td>[1. 1.]</td>\n",
       "      <td>97</td>\n",
       "      <td>2</td>\n",
       "      <td>0.360825</td>\n",
       "      <td>0.072165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adult_cleaned</td>\n",
       "      <td>lr</td>\n",
       "      <td>local</td>\n",
       "      <td>lime</td>\n",
       "      <td>10</td>\n",
       "      <td>JTT</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>output\\eff_lr_lime_adult_cleaned</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.942752</td>\n",
       "      <td>0.188946</td>\n",
       "      <td>0.967275</td>\n",
       "      <td>0.970954</td>\n",
       "      <td>-0.285672</td>\n",
       "      <td>[0. 2.]</td>\n",
       "      <td>241</td>\n",
       "      <td>2</td>\n",
       "      <td>0.033195</td>\n",
       "      <td>0.004149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>adult_cleaned</td>\n",
       "      <td>lr</td>\n",
       "      <td>local</td>\n",
       "      <td>lime</td>\n",
       "      <td>10</td>\n",
       "      <td>JTT</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>output\\robust_jtt</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.942048</td>\n",
       "      <td>0.188946</td>\n",
       "      <td>0.941735</td>\n",
       "      <td>0.832567</td>\n",
       "      <td>-0.133111</td>\n",
       "      <td>[nan  4.]</td>\n",
       "      <td>4133</td>\n",
       "      <td>1</td>\n",
       "      <td>0.200097</td>\n",
       "      <td>0.032664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>adult_cleaned</td>\n",
       "      <td>lr</td>\n",
       "      <td>local</td>\n",
       "      <td>lime</td>\n",
       "      <td>10</td>\n",
       "      <td>JTT</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>output\\robust_jtt</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.942048</td>\n",
       "      <td>0.188946</td>\n",
       "      <td>0.947928</td>\n",
       "      <td>0.920233</td>\n",
       "      <td>-0.229226</td>\n",
       "      <td>[nan  2.]</td>\n",
       "      <td>514</td>\n",
       "      <td>1</td>\n",
       "      <td>0.089494</td>\n",
       "      <td>0.017510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>adult_cleaned</td>\n",
       "      <td>lr</td>\n",
       "      <td>local</td>\n",
       "      <td>lime</td>\n",
       "      <td>10</td>\n",
       "      <td>JTT</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>output\\robust_jtt</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.942048</td>\n",
       "      <td>0.188946</td>\n",
       "      <td>0.939920</td>\n",
       "      <td>0.791946</td>\n",
       "      <td>-0.109621</td>\n",
       "      <td>[nan  1.]</td>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "      <td>0.281879</td>\n",
       "      <td>0.073826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>adult_cleaned</td>\n",
       "      <td>lr</td>\n",
       "      <td>local</td>\n",
       "      <td>lime</td>\n",
       "      <td>10</td>\n",
       "      <td>JTT</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>output\\robust_jtt</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.942048</td>\n",
       "      <td>0.188946</td>\n",
       "      <td>0.948052</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>-0.208897</td>\n",
       "      <td>[nan  3.]</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>0.137255</td>\n",
       "      <td>0.019608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>adult_cleaned</td>\n",
       "      <td>lr</td>\n",
       "      <td>local</td>\n",
       "      <td>lime</td>\n",
       "      <td>10</td>\n",
       "      <td>JTT</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>output\\robust_jtt</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.942048</td>\n",
       "      <td>0.188946</td>\n",
       "      <td>0.972973</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>-0.240512</td>\n",
       "      <td>[nan  0.]</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.026316</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          dataset blackbox_model explanation_type explanation_model  \\\n",
       "0   adult_cleaned             lr            local              lime   \n",
       "1   adult_cleaned             lr            local              lime   \n",
       "2   adult_cleaned             lr            local              lime   \n",
       "3   adult_cleaned             lr            local              lime   \n",
       "4   adult_cleaned             lr            local              lime   \n",
       "..            ...            ...              ...               ...   \n",
       "63  adult_cleaned             lr            local              lime   \n",
       "64  adult_cleaned             lr            local              lime   \n",
       "65  adult_cleaned             lr            local              lime   \n",
       "66  adult_cleaned             lr            local              lime   \n",
       "67  adult_cleaned             lr            local              lime   \n",
       "\n",
       "    n_features model_type  seed experiment                        output_dir  \\\n",
       "0           10        JTT     1             output\\eff_lr_lime_adult_cleaned   \n",
       "1           10        JTT     1             output\\eff_lr_lime_adult_cleaned   \n",
       "2           10        JTT     1             output\\eff_lr_lime_adult_cleaned   \n",
       "3           10        JTT     1             output\\eff_lr_lime_adult_cleaned   \n",
       "4           10        JTT     1             output\\eff_lr_lime_adult_cleaned   \n",
       "..         ...        ...   ...        ...                               ...   \n",
       "63          10        JTT     1                            output\\robust_jtt   \n",
       "64          10        JTT     1                            output\\robust_jtt   \n",
       "65          10        JTT     1                            output\\robust_jtt   \n",
       "66          10        JTT     1                            output\\robust_jtt   \n",
       "67          10        JTT     1                            output\\robust_jtt   \n",
       "\n",
       "    ignore_lime_weights  ...  auroc_all  prevalence_all     AUROC       ACC  \\\n",
       "0                 False  ...   0.942752        0.188946  0.941252  0.783150   \n",
       "1                 False  ...   0.942752        0.188946  0.950840  0.879121   \n",
       "2                 False  ...   0.942752        0.188946  0.957388  0.938636   \n",
       "3                 False  ...   0.942752        0.188946  0.896774  0.711340   \n",
       "4                 False  ...   0.942752        0.188946  0.967275  0.970954   \n",
       "..                  ...  ...        ...             ...       ...       ...   \n",
       "63                False  ...   0.942048        0.188946  0.941735  0.832567   \n",
       "64                False  ...   0.942048        0.188946  0.947928  0.920233   \n",
       "65                False  ...   0.942048        0.188946  0.939920  0.791946   \n",
       "66                False  ...   0.942048        0.188946  0.948052  0.882353   \n",
       "67                False  ...   0.942048        0.188946  0.972973  0.947368   \n",
       "\n",
       "     epsilon      group     n level  prevalence  pred_prevalence  \n",
       "0  -0.082286    [1. 4.]  2813     2    0.257732         0.040882  \n",
       "1  -0.179015    [1. 2.]   273     2    0.139194         0.025641  \n",
       "2  -0.242103    [0. 4.]  1320     2    0.077273         0.015909  \n",
       "3  -0.041104    [1. 1.]    97     2    0.360825         0.072165  \n",
       "4  -0.285672    [0. 2.]   241     2    0.033195         0.004149  \n",
       "..       ...        ...   ...   ...         ...              ...  \n",
       "63 -0.133111  [nan  4.]  4133     1    0.200097         0.032664  \n",
       "64 -0.229226  [nan  2.]   514     1    0.089494         0.017510  \n",
       "65 -0.109621  [nan  1.]   149     1    0.281879         0.073826  \n",
       "66 -0.208897  [nan  3.]    51     1    0.137255         0.019608  \n",
       "67 -0.240512  [nan  0.]    38     1    0.026316         0.026316  \n",
       "\n",
       "[68 rows x 40 columns]"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sel=pd.DataFrame(df_raw)\n",
    "lsac_mean = df_sel[df_sel['dataset'] == 'lsac'].mean()\n",
    "for key in list(lsac_mean.keys()):\n",
    "    df_sel[key] = df_sel[key].fillna(lsac_mean[key])\n",
    "# df_sel=df_sel[((df_sel.dataset!='lsac')&(df_sel.balance_labels==balance_labels_ind))|\n",
    "#             #   ((df_sel.dataset=='lsac')&(df_sel.balance_labels==True))\n",
    "#               ((df_sel.dataset=='lsac')&(df_sel.balance_labels==False))\n",
    "#              ]\n",
    "df_sel=df_sel[df_sel.balance_groups==balance_group_ind]\n",
    "df_sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "LEVEL = 1\n",
    "df=df_sel\n",
    "# df=df[df.seed.isin([1,2,3,4,5])]\n",
    "# df=df[(df.experiment.isin(['lime_balanced_correct_replication']))]\n",
    "\n",
    "res_df = df.query(f'level == {LEVEL}').groupby('output_dir').apply(agg_func)\n",
    "\n",
    "metrics = [i for i in res_df.columns if not i.startswith('worst_group')]\n",
    "out1 = (res_df\n",
    "     .reset_index()\n",
    "     .merge(df[hparams + ['output_dir', 'seed', 'hparam_id']].drop_duplicates()))\n",
    "\n",
    "out2 = (out1.groupby('hparam_id').agg({\n",
    "   i: ('mean', 'std') for i in metrics\n",
    "})\n",
    "       .merge(df[hparams + ['hparam_id']].drop_duplicates().set_index('hparam_id'), left_index = True, right_index = True)\n",
    "       .reset_index())\n",
    "\n",
    "for col in metrics:\n",
    "    # out2[col] = out2[(col, 'mean')].apply(lambda x: '{0:.001%}'.format(x)) +' ± ' +  out2[(col, 'std')].apply(lambda x: '{0:.001%}'.format(x))\n",
    "    out2[col] = out2[(col, 'mean')].apply(lambda x: '{0:.001%}'.format(x))\n",
    "\n",
    "\n",
    "out_all=out2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_all.to_csv(\"temp.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hparam_id                0\n",
      "(accuracy_all, mean)     0\n",
      "(accuracy_all, std)      2\n",
      "(accuracy_min, mean)     0\n",
      "(accuracy_min, std)      2\n",
      "                        ..\n",
      "epsilon_[nan  0.]_gap    0\n",
      "epsilon_[nan  1.]_gap    0\n",
      "epsilon_[nan  2.]_gap    0\n",
      "epsilon_[nan  3.]_gap    0\n",
      "epsilon_[nan  4.]_gap    0\n",
      "Length: 195, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(out_all.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          hparam_id  (accuracy_all, mean)  \\\n",
      "0  2cef927231ffee39fae33dacee461442              0.835005   \n",
      "1  a01bc04600b589cc9d0515b9f02d3191              0.609826   \n",
      "2  fdc93bbcf478c07466f2bcc90a281a34              0.842068   \n",
      "\n",
      "   (accuracy_all, std)  (accuracy_min, mean)  (accuracy_min, std)  \\\n",
      "0                  NaN              0.778523                  NaN   \n",
      "1                  NaN              0.526316                  NaN   \n",
      "2             0.000145              0.787858              0.00371   \n",
      "\n",
      "   (accuracy_minority, mean)  (accuracy_minority, std)  \\\n",
      "0                   0.947368                       NaN   \n",
      "1                   0.526316                       NaN   \n",
      "2                   0.947368                       0.0   \n",
      "\n",
      "   (accuracy_majority, mean)  (accuracy_majority, std)  (accuracy_gap, mean)  \\\n",
      "0                   0.824825                       NaN              0.056482   \n",
      "1                   0.609485                       NaN              0.083510   \n",
      "2                   0.832688                  0.000171              0.054209   \n",
      "\n",
      "   ...  epsilon_[nan  1.]_gap  epsilon_[nan  2.]_gap  epsilon_[nan  3.]_gap  \\\n",
      "0  ...                  -7.3%                   5.0%                   3.1%   \n",
      "1  ...                  -8.5%                   5.0%                   4.2%   \n",
      "2  ...                  -7.1%                   4.9%                   2.9%   \n",
      "\n",
      "   epsilon_[nan  4.]_gap  auroc_max_gap  auroc_sens_gap  accuracy_max_gap  \\\n",
      "0                  -4.8%           0.3%            2.5%              5.4%   \n",
      "1                  -4.6%           1.6%            6.3%              1.8%   \n",
      "2                  -4.7%           0.4%            2.1%              5.1%   \n",
      "\n",
      "   accuracy_sens_gap  epsilon_max_gap  epsilon_sens_gap  \n",
      "0              16.0%             7.0%             16.2%  \n",
      "1               5.3%             6.8%             15.6%  \n",
      "2              15.2%             6.8%             15.8%  \n",
      "\n",
      "[3 rows x 201 columns]\n"
     ]
    }
   ],
   "source": [
    "auroc_gaps=[]\n",
    "acc_gaps=[]\n",
    "for sig in np.sort(out_all.perturb_sigma.unique()):\n",
    "    temp1 = out_all\n",
    "    # temp1=out_all[(out_all.explanation_type=='local')&\n",
    "    #               (out_all.blackbox_model.isin(['lr','nn']))&\n",
    "    #              (out_all.perturb_sigma==sig)]\n",
    "    \n",
    "    # temp1=temp1[temp1.n_features.isin([100])]\n",
    "    # temp1=temp1[(temp1.explanation_model=='shap_blackbox_preprocessed')|\n",
    "    #            (temp1.explanation_model=='lime')|\n",
    "    #            (temp1.explanation_model=='lime_test')|\n",
    "    #             (temp1.explanation_model=='lime_test_new')\n",
    "    #            ]\n",
    "    # temp1.loc[temp1.explanation_model=='shap_blackbox_preprocessed','explanation_model']='SHAP'\n",
    "    # temp1.loc[temp1.explanation_model=='lime','explanation_model']='LIME'\n",
    "    # temp1 = temp1[temp1.dataset.isin(['adult','mimic_tab_robust','lsac','adult_cleaned','compas_balanced'])]\n",
    "    # temp1 = temp1[temp1.explanation_model.isin(['LIME','SHAP'])]\n",
    "\n",
    "    for perf_metric in ['auroc','accuracy','epsilon']:\n",
    "        temp1[f'{perf_metric}_max_gap']=temp1.apply(lambda row: get_max_gap_row(row,perf_metric,\n",
    "                                                                       list_groups=list_groups_dict[row['dataset']]), axis=1)\n",
    "        temp1[f'{perf_metric}_sens_gap']=temp1.apply(lambda row: row[f'{perf_metric}_sens{sens_feature_dict[row.dataset]}_gap'],axis=1)\n",
    "        \n",
    "print(temp1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>accuracy_max_gap</th>\n",
       "      <th>accuracy_sens_gap</th>\n",
       "      <th>auroc_all</th>\n",
       "      <th>auroc_sens_gap</th>\n",
       "      <th>epsilon_sens_gap</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <th>blackbox_model</th>\n",
       "      <th>explanation_model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>adult_cleaned</th>\n",
       "      <th>lr</th>\n",
       "      <th>lime</th>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               accuracy_max_gap  \\\n",
       "dataset       blackbox_model explanation_model                    \n",
       "adult_cleaned lr             lime                            []   \n",
       "\n",
       "                                               accuracy_sens_gap auroc_all  \\\n",
       "dataset       blackbox_model explanation_model                               \n",
       "adult_cleaned lr             lime                             []        []   \n",
       "\n",
       "                                               auroc_sens_gap epsilon_sens_gap  \n",
       "dataset       blackbox_model explanation_model                                  \n",
       "adult_cleaned lr             lime                          []               []  "
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_reported_table1=['auroc_all',\n",
    "                 'accuracy_max_gap',\n",
    "                  'auroc_sens_gap',\n",
    "                 'accuracy_sens_gap',\n",
    "                 'epsilon_sens_gap'\n",
    "                      ]\n",
    "# temp1=temp1[temp1.explanation_model=='LIME']\n",
    "res = pd.pivot_table(data=temp1[['dataset','blackbox_model','explanation_model']+metrics_reported_table1],\n",
    "               values=metrics_reported_table1,  index = ['dataset', 'blackbox_model','explanation_model'], \n",
    "                                                    aggfunc = lambda x: x,\n",
    "                                                    )\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lllllllllll}\n",
      "\\toprule\n",
      "{} &        dataset & blackbox\\_model & explanation\\_model & auroc\\_all & auroc\\_max\\_gap & accuracy\\_max\\_gap & auroc\\_sens\\_gap & accuracy\\_sens\\_gap & epsilon\\_sens\\_gap & model\\_type \\\\\n",
      "\\midrule\n",
      "0 &  adult\\_cleaned &             lr &              lime &     92.7\\% &          0.3\\% &             5.4\\% &           2.5\\% &             16.0\\% &            16.2\\% &       IJTT \\\\\n",
      "1 &  adult\\_cleaned &             lr &              lime &     60.1\\% &          1.6\\% &             1.8\\% &           6.3\\% &              5.3\\% &            15.6\\% &   JointDRO \\\\\n",
      "2 &  adult\\_cleaned &             lr &              lime &     94.2\\% &          0.4\\% &             5.1\\% &           2.1\\% &             15.2\\% &            15.8\\% &        JTT \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# temp1=temp1[temp1.explanation_model.isin(['LIME'])]\n",
    "print(temp1[['dataset','blackbox_model','explanation_model',\n",
    "             'auroc_all',\n",
    "             'auroc_max_gap',\n",
    "             'accuracy_max_gap',\n",
    "             'auroc_sens_gap',\n",
    "             'accuracy_sens_gap',\n",
    "             'epsilon_sens_gap',\n",
    "             'model_type'\n",
    "             ]].sort_values(['dataset','blackbox_model','explanation_model']).to_latex())\n",
    "# print(res.to_latex())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>blackbox_model</th>\n",
       "      <th>explanation_model</th>\n",
       "      <th>auroc_all</th>\n",
       "      <th>auroc_max_gap</th>\n",
       "      <th>accuracy_max_gap</th>\n",
       "      <th>auroc_sens_gap</th>\n",
       "      <th>accuracy_sens_gap</th>\n",
       "      <th>epsilon_sens_gap</th>\n",
       "      <th>model_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>adult_cleaned</td>\n",
       "      <td>lr</td>\n",
       "      <td>lime</td>\n",
       "      <td>92.7%</td>\n",
       "      <td>0.3%</td>\n",
       "      <td>5.4%</td>\n",
       "      <td>2.5%</td>\n",
       "      <td>16.0%</td>\n",
       "      <td>16.2%</td>\n",
       "      <td>IJTT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>adult_cleaned</td>\n",
       "      <td>lr</td>\n",
       "      <td>lime</td>\n",
       "      <td>60.1%</td>\n",
       "      <td>1.6%</td>\n",
       "      <td>1.8%</td>\n",
       "      <td>6.3%</td>\n",
       "      <td>5.3%</td>\n",
       "      <td>15.6%</td>\n",
       "      <td>JointDRO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>adult_cleaned</td>\n",
       "      <td>lr</td>\n",
       "      <td>lime</td>\n",
       "      <td>94.2%</td>\n",
       "      <td>0.4%</td>\n",
       "      <td>5.1%</td>\n",
       "      <td>2.1%</td>\n",
       "      <td>15.2%</td>\n",
       "      <td>15.8%</td>\n",
       "      <td>JTT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         dataset blackbox_model explanation_model auroc_all auroc_max_gap  \\\n",
       "0  adult_cleaned             lr              lime     92.7%          0.3%   \n",
       "1  adult_cleaned             lr              lime     60.1%          1.6%   \n",
       "2  adult_cleaned             lr              lime     94.2%          0.4%   \n",
       "\n",
       "  accuracy_max_gap auroc_sens_gap accuracy_sens_gap epsilon_sens_gap  \\\n",
       "0             5.4%           2.5%             16.0%            16.2%   \n",
       "1             1.8%           6.3%              5.3%            15.6%   \n",
       "2             5.1%           2.1%             15.2%            15.8%   \n",
       "\n",
       "  model_type  \n",
       "0       IJTT  \n",
       "1   JointDRO  \n",
       "2        JTT  "
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp1[['dataset','blackbox_model','explanation_model',\n",
    "             'auroc_all',\n",
    "             'auroc_max_gap',\n",
    "             'accuracy_max_gap',\n",
    "             'auroc_sens_gap',\n",
    "             'accuracy_sens_gap',\n",
    "             'epsilon_sens_gap',\n",
    "             'model_type'\n",
    "             ]].sort_values(['dataset','blackbox_model','explanation_model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
