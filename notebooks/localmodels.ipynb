{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import hashlib\n",
    "import json\n",
    "from pathlib import Path\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_auc_score, auc, roc_curve\n",
    "from sklearn import metrics\n",
    "import warnings\n",
    "# NB: Warnings occur when computing metrics for groups with\n",
    "# low sample sizes. In our case, we don't use the metrics \n",
    "# for these groups.\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from compute_metrics import Model\n",
    "from lib.TabularDataset import dataset_params\n",
    "from lib import TabularDataset\n",
    "from result_latex_utils import agg_func\n",
    "# from result_latex_utils import meanPairDiff, agg_func, bold_max\n",
    "\n",
    "\n",
    "# res_dir = Path('/scratch/ssd001/home/aparna/explanations-subpopulations/output_main')\n",
    "res_dir = Path('../output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('../output/exp0/lr_local_lime.csv')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retain column names\n",
    "retain_cols=False\n",
    "list(res_dir.glob('**/*.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_raw = []\n",
    "for path in res_dir.glob('**/*.csv'):\n",
    "    args = json.load((path.parent/'args.json').open('r'))\n",
    "    # all settings for paper table 1\n",
    "    #'lime','shap_blackbox_preprocessed',\n",
    "    if args['explanation_type']=='local' and args['dataset'] in ['adult','compas_balanced','lsac','adult_cleaned','mimic_tab_robust','mimic_tab_fair_ds']:# and args['explanation_model'] in ['lime_test_new','lime_test','lime','shap_blackbox_preprocessed']:\n",
    "        hparams = [i for i in list(args.keys()) if i not in ['seed', 'output_dir']]\n",
    "        args['hparam_id'] = hashlib.md5(str([args[i] for i in hparams]).encode('utf-8')).hexdigest()\n",
    "        \n",
    "        \n",
    "        res = pd.read_csv(path)\n",
    "        \n",
    "        # get performance on test set\n",
    "        res = res[res.set=='test']\n",
    "\n",
    "        if res.shape[0]>0:\n",
    "            dataset = TabularDataset.Dataset(args['dataset'])\n",
    "            X_train, X_train_expl, X_val_expl, X_test, y_train, y_train_expl, y_val_expl, y_test, g_train, g_train_expl, g_val_expl, g_test = dataset.get_data(\n",
    "            retain_cols=retain_cols)\n",
    "            \n",
    "            # to check that the whole test set is present\n",
    "            assert res.shape[0]==g_test.shape[0]\n",
    "            res[dataset_params[args['dataset']].sensitive_attributes] = g_test.values\n",
    "            assert res[res['blackbox_prob'].isna()].shape[0]==0\n",
    "            assert res[res['expl_pred'].isna()].shape[0]==0\n",
    "                            \n",
    "            if sum(~np.isfinite(res['expl_pred'].values))>0:\n",
    "                raise ValueError('For dataset {}, model {}'.format(args['dataset'],\n",
    "                                                                  args['explanation_model']))\n",
    "                \n",
    "            # compute metrics over all items in test set\n",
    "            args['accuracy_all'] = ((res['expl_pred'].values >= 0.5) == res[\n",
    "                                          'blackbox_pred']).sum() / len(res)\n",
    "            fpr, tpr, thresholds = roc_curve(res['blackbox_pred'].values, res['expl_pred'].values\n",
    "                                             , pos_label=1)\n",
    "            roc = metrics.auc(fpr, tpr)\n",
    "            args['auroc_all'] = roc\n",
    "            args['prevalence_all']= res['blackbox_pred'].mean()\n",
    "\n",
    "            group_names = dataset_params[args['dataset']].sensitive_attributes\n",
    "            unique_groups = res[group_names].drop_duplicates()\n",
    "            for grp in group_names:\n",
    "                for val in res[grp].unique():\n",
    "                    unique_groups = unique_groups.append({grp: \n",
    "                                                          val, **{i: np.nan for i in group_names if i != grp}}, \n",
    "                                                         ignore_index = True)\n",
    "\n",
    "            for group in range(unique_groups.shape[0]):\n",
    "                group_i = unique_groups.iloc[group].values\n",
    "                \n",
    "                mask = ~pd.isnull(group_i)\n",
    "                curr_group_names = np.array(group_names)[mask]\n",
    "                curr_group_vals = group_i[mask]\n",
    "                sel_rows1 = res[(res[np.array(group_names)[mask]].values ==\n",
    "                       group_i[mask]).all(1)]\n",
    "                \n",
    "                # if we have 2 sensitive group columns\n",
    "                if len(curr_group_names)==2:\n",
    "                    sel_rows = res[(res[curr_group_names[0]]== curr_group_vals[0])&\n",
    "                                   (res[curr_group_names[1]]== curr_group_vals[1])]\n",
    "                elif len(curr_group_names)==1:\n",
    "                    sel_rows = res[res[curr_group_names[0]]== curr_group_vals[0]]\n",
    "                else:\n",
    "                    print('Warning: Default setting!')\n",
    "                    sel_rows = res\n",
    "                \n",
    "                # checking that logic of row selection works \n",
    "                assert sel_rows1.equals(sel_rows)\n",
    "                \n",
    "                # computing performance on given group\n",
    "                group_0_val_model = Model(sel_rows['expl_pred'].values, sel_rows[\n",
    "                                          'blackbox_pred'].values,\n",
    "                                         sel_rows[\n",
    "                                          'blackbox_prob'].values)\n",
    "                all_metrics = group_0_val_model.compute()\n",
    "                args_group = {\n",
    "                    **copy.deepcopy(args),\n",
    "                    **all_metrics\n",
    "                             }\n",
    "                # some metadata\n",
    "                args_group['group'] = str(unique_groups.iloc[group].values)\n",
    "                args_group['n'] = len(sel_rows)\n",
    "                args_group['level'] = mask.sum()\n",
    "                args_group['prevalence'] = sel_rows['blackbox_pred'].mean()\n",
    "                args_group['pred_prevalence'] = np.mean(sel_rows['expl_pred']>=0.5)\n",
    "                df_raw.append(args_group)\n",
    "                # print(args_group)\n",
    "\n",
    "df_local = pd.DataFrame(df_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gender', 'race']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_params[df_local['dataset'][0]].sensitive_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['dataset', 'blackbox_model', 'explanation_type', 'explanation_model',\n",
       "       'n_features', 'model_type', 'seed', 'experiment', 'output_dir',\n",
       "       'ignore_lime_weights', 'evaluate_val', 'max_epochs', 'perturb_sigma',\n",
       "       'balance_groups', 'balance_labels', 'balance_group_idx',\n",
       "       'train_grp_clf', 'grp_clf_attr', 'lr', 'C', 'batch_size', 'debug',\n",
       "       'jtt_lambda', 'jtt_thres', 'joint_dro_alpha', 'groupdro_eta',\n",
       "       'tree_depth', 'gam_max_iter', 'hparam_id', 'accuracy_all', 'auroc_all',\n",
       "       'prevalence_all', 'AUROC', 'ACC', 'epsilon', 'group', 'n', 'level',\n",
       "       'prevalence', 'pred_prevalence'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_local.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [1. 4.]\n",
       "1       [1. 2.]\n",
       "2       [0. 4.]\n",
       "3       [1. 1.]\n",
       "4       [0. 2.]\n",
       "5       [1. 3.]\n",
       "6       [0. 1.]\n",
       "7       [0. 0.]\n",
       "8       [1. 0.]\n",
       "9       [0. 3.]\n",
       "10    [ 1. nan]\n",
       "11    [ 0. nan]\n",
       "12    [nan  4.]\n",
       "13    [nan  2.]\n",
       "14    [nan  1.]\n",
       "15    [nan  3.]\n",
       "16    [nan  0.]\n",
       "Name: group, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_local.group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>blackbox_model</th>\n",
       "      <th>explanation_type</th>\n",
       "      <th>explanation_model</th>\n",
       "      <th>n_features</th>\n",
       "      <th>model_type</th>\n",
       "      <th>seed</th>\n",
       "      <th>experiment</th>\n",
       "      <th>output_dir</th>\n",
       "      <th>ignore_lime_weights</th>\n",
       "      <th>...</th>\n",
       "      <th>auroc_all</th>\n",
       "      <th>prevalence_all</th>\n",
       "      <th>AUROC</th>\n",
       "      <th>ACC</th>\n",
       "      <th>epsilon</th>\n",
       "      <th>group</th>\n",
       "      <th>n</th>\n",
       "      <th>level</th>\n",
       "      <th>prevalence</th>\n",
       "      <th>pred_prevalence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>adult_cleaned</td>\n",
       "      <td>lr</td>\n",
       "      <td>local</td>\n",
       "      <td>lime</td>\n",
       "      <td>5</td>\n",
       "      <td>sklearn</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>output\\exp0</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.976128</td>\n",
       "      <td>0.188946</td>\n",
       "      <td>0.969214</td>\n",
       "      <td>0.899396</td>\n",
       "      <td>-0.037344</td>\n",
       "      <td>[1. 4.]</td>\n",
       "      <td>2813</td>\n",
       "      <td>2</td>\n",
       "      <td>0.257732</td>\n",
       "      <td>0.185567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>adult_cleaned</td>\n",
       "      <td>lr</td>\n",
       "      <td>local</td>\n",
       "      <td>lime</td>\n",
       "      <td>5</td>\n",
       "      <td>sklearn</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>output\\exp0</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.976128</td>\n",
       "      <td>0.188946</td>\n",
       "      <td>0.988466</td>\n",
       "      <td>0.959707</td>\n",
       "      <td>-0.054139</td>\n",
       "      <td>[1. 2.]</td>\n",
       "      <td>273</td>\n",
       "      <td>2</td>\n",
       "      <td>0.139194</td>\n",
       "      <td>0.120879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>adult_cleaned</td>\n",
       "      <td>lr</td>\n",
       "      <td>local</td>\n",
       "      <td>lime</td>\n",
       "      <td>5</td>\n",
       "      <td>sklearn</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>output\\exp0</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.976128</td>\n",
       "      <td>0.188946</td>\n",
       "      <td>0.991919</td>\n",
       "      <td>0.962121</td>\n",
       "      <td>-0.051018</td>\n",
       "      <td>[0. 4.]</td>\n",
       "      <td>1320</td>\n",
       "      <td>2</td>\n",
       "      <td>0.077273</td>\n",
       "      <td>0.039394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>adult_cleaned</td>\n",
       "      <td>lr</td>\n",
       "      <td>local</td>\n",
       "      <td>lime</td>\n",
       "      <td>5</td>\n",
       "      <td>sklearn</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>output\\exp0</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.976128</td>\n",
       "      <td>0.188946</td>\n",
       "      <td>0.982949</td>\n",
       "      <td>0.876289</td>\n",
       "      <td>-0.026053</td>\n",
       "      <td>[1. 1.]</td>\n",
       "      <td>97</td>\n",
       "      <td>2</td>\n",
       "      <td>0.360825</td>\n",
       "      <td>0.237113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adult_cleaned</td>\n",
       "      <td>lr</td>\n",
       "      <td>local</td>\n",
       "      <td>lime</td>\n",
       "      <td>5</td>\n",
       "      <td>sklearn</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>output\\exp0</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.976128</td>\n",
       "      <td>0.188946</td>\n",
       "      <td>0.987124</td>\n",
       "      <td>0.975104</td>\n",
       "      <td>-0.070134</td>\n",
       "      <td>[0. 2.]</td>\n",
       "      <td>241</td>\n",
       "      <td>2</td>\n",
       "      <td>0.033195</td>\n",
       "      <td>0.016598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>adult_cleaned</td>\n",
       "      <td>lr</td>\n",
       "      <td>local</td>\n",
       "      <td>lime</td>\n",
       "      <td>5</td>\n",
       "      <td>sklearn</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>output\\exp0</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.976128</td>\n",
       "      <td>0.188946</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>-0.060338</td>\n",
       "      <td>[1. 3.]</td>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "      <td>0.147059</td>\n",
       "      <td>0.088235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>adult_cleaned</td>\n",
       "      <td>lr</td>\n",
       "      <td>local</td>\n",
       "      <td>lime</td>\n",
       "      <td>5</td>\n",
       "      <td>sklearn</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>output\\exp0</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.976128</td>\n",
       "      <td>0.188946</td>\n",
       "      <td>0.993651</td>\n",
       "      <td>0.942308</td>\n",
       "      <td>-0.073319</td>\n",
       "      <td>[0. 1.]</td>\n",
       "      <td>52</td>\n",
       "      <td>2</td>\n",
       "      <td>0.134615</td>\n",
       "      <td>0.076923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>adult_cleaned</td>\n",
       "      <td>lr</td>\n",
       "      <td>local</td>\n",
       "      <td>lime</td>\n",
       "      <td>5</td>\n",
       "      <td>sklearn</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>output\\exp0</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.976128</td>\n",
       "      <td>0.188946</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>-0.063535</td>\n",
       "      <td>[0. 0.]</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>adult_cleaned</td>\n",
       "      <td>lr</td>\n",
       "      <td>local</td>\n",
       "      <td>lime</td>\n",
       "      <td>5</td>\n",
       "      <td>sklearn</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>output\\exp0</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.976128</td>\n",
       "      <td>0.188946</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>-0.123173</td>\n",
       "      <td>[1. 0.]</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.052632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>adult_cleaned</td>\n",
       "      <td>lr</td>\n",
       "      <td>local</td>\n",
       "      <td>lime</td>\n",
       "      <td>5</td>\n",
       "      <td>sklearn</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>output\\exp0</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.976128</td>\n",
       "      <td>0.188946</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>-0.033220</td>\n",
       "      <td>[0. 3.]</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>adult_cleaned</td>\n",
       "      <td>lr</td>\n",
       "      <td>local</td>\n",
       "      <td>lime</td>\n",
       "      <td>5</td>\n",
       "      <td>sklearn</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>output\\exp0</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.976128</td>\n",
       "      <td>0.188946</td>\n",
       "      <td>0.971566</td>\n",
       "      <td>0.904512</td>\n",
       "      <td>-0.039168</td>\n",
       "      <td>[ 1. nan]</td>\n",
       "      <td>3236</td>\n",
       "      <td>1</td>\n",
       "      <td>0.248146</td>\n",
       "      <td>0.179852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>adult_cleaned</td>\n",
       "      <td>lr</td>\n",
       "      <td>local</td>\n",
       "      <td>lime</td>\n",
       "      <td>5</td>\n",
       "      <td>sklearn</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>output\\exp0</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.976128</td>\n",
       "      <td>0.188946</td>\n",
       "      <td>0.991885</td>\n",
       "      <td>0.962401</td>\n",
       "      <td>-0.054476</td>\n",
       "      <td>[ 0. nan]</td>\n",
       "      <td>1649</td>\n",
       "      <td>1</td>\n",
       "      <td>0.072771</td>\n",
       "      <td>0.036386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>adult_cleaned</td>\n",
       "      <td>lr</td>\n",
       "      <td>local</td>\n",
       "      <td>lime</td>\n",
       "      <td>5</td>\n",
       "      <td>sklearn</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>output\\exp0</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.976128</td>\n",
       "      <td>0.188946</td>\n",
       "      <td>0.974426</td>\n",
       "      <td>0.919429</td>\n",
       "      <td>-0.041711</td>\n",
       "      <td>[nan  4.]</td>\n",
       "      <td>4133</td>\n",
       "      <td>1</td>\n",
       "      <td>0.200097</td>\n",
       "      <td>0.138882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>adult_cleaned</td>\n",
       "      <td>lr</td>\n",
       "      <td>local</td>\n",
       "      <td>lime</td>\n",
       "      <td>5</td>\n",
       "      <td>sklearn</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>output\\exp0</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.976128</td>\n",
       "      <td>0.188946</td>\n",
       "      <td>0.986576</td>\n",
       "      <td>0.966926</td>\n",
       "      <td>-0.061638</td>\n",
       "      <td>[nan  2.]</td>\n",
       "      <td>514</td>\n",
       "      <td>1</td>\n",
       "      <td>0.089494</td>\n",
       "      <td>0.071984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>adult_cleaned</td>\n",
       "      <td>lr</td>\n",
       "      <td>local</td>\n",
       "      <td>lime</td>\n",
       "      <td>5</td>\n",
       "      <td>sklearn</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>output\\exp0</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.976128</td>\n",
       "      <td>0.188946</td>\n",
       "      <td>0.983979</td>\n",
       "      <td>0.899329</td>\n",
       "      <td>-0.042548</td>\n",
       "      <td>[nan  1.]</td>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "      <td>0.281879</td>\n",
       "      <td>0.181208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>adult_cleaned</td>\n",
       "      <td>lr</td>\n",
       "      <td>local</td>\n",
       "      <td>lime</td>\n",
       "      <td>5</td>\n",
       "      <td>sklearn</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>output\\exp0</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.976128</td>\n",
       "      <td>0.188946</td>\n",
       "      <td>0.980519</td>\n",
       "      <td>0.921569</td>\n",
       "      <td>-0.051299</td>\n",
       "      <td>[nan  3.]</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>0.137255</td>\n",
       "      <td>0.058824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>adult_cleaned</td>\n",
       "      <td>lr</td>\n",
       "      <td>local</td>\n",
       "      <td>lime</td>\n",
       "      <td>5</td>\n",
       "      <td>sklearn</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>output\\exp0</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.976128</td>\n",
       "      <td>0.188946</td>\n",
       "      <td>0.972973</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>-0.093354</td>\n",
       "      <td>[nan  0.]</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.026316</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          dataset blackbox_model explanation_type explanation_model  \\\n",
       "0   adult_cleaned             lr            local              lime   \n",
       "1   adult_cleaned             lr            local              lime   \n",
       "2   adult_cleaned             lr            local              lime   \n",
       "3   adult_cleaned             lr            local              lime   \n",
       "4   adult_cleaned             lr            local              lime   \n",
       "5   adult_cleaned             lr            local              lime   \n",
       "6   adult_cleaned             lr            local              lime   \n",
       "7   adult_cleaned             lr            local              lime   \n",
       "8   adult_cleaned             lr            local              lime   \n",
       "9   adult_cleaned             lr            local              lime   \n",
       "10  adult_cleaned             lr            local              lime   \n",
       "11  adult_cleaned             lr            local              lime   \n",
       "12  adult_cleaned             lr            local              lime   \n",
       "13  adult_cleaned             lr            local              lime   \n",
       "14  adult_cleaned             lr            local              lime   \n",
       "15  adult_cleaned             lr            local              lime   \n",
       "16  adult_cleaned             lr            local              lime   \n",
       "\n",
       "    n_features model_type  seed experiment   output_dir  ignore_lime_weights  \\\n",
       "0            5    sklearn     1             output\\exp0                False   \n",
       "1            5    sklearn     1             output\\exp0                False   \n",
       "2            5    sklearn     1             output\\exp0                False   \n",
       "3            5    sklearn     1             output\\exp0                False   \n",
       "4            5    sklearn     1             output\\exp0                False   \n",
       "5            5    sklearn     1             output\\exp0                False   \n",
       "6            5    sklearn     1             output\\exp0                False   \n",
       "7            5    sklearn     1             output\\exp0                False   \n",
       "8            5    sklearn     1             output\\exp0                False   \n",
       "9            5    sklearn     1             output\\exp0                False   \n",
       "10           5    sklearn     1             output\\exp0                False   \n",
       "11           5    sklearn     1             output\\exp0                False   \n",
       "12           5    sklearn     1             output\\exp0                False   \n",
       "13           5    sklearn     1             output\\exp0                False   \n",
       "14           5    sklearn     1             output\\exp0                False   \n",
       "15           5    sklearn     1             output\\exp0                False   \n",
       "16           5    sklearn     1             output\\exp0                False   \n",
       "\n",
       "    ...  auroc_all  prevalence_all     AUROC       ACC   epsilon      group  \\\n",
       "0   ...   0.976128        0.188946  0.969214  0.899396 -0.037344    [1. 4.]   \n",
       "1   ...   0.976128        0.188946  0.988466  0.959707 -0.054139    [1. 2.]   \n",
       "2   ...   0.976128        0.188946  0.991919  0.962121 -0.051018    [0. 4.]   \n",
       "3   ...   0.976128        0.188946  0.982949  0.876289 -0.026053    [1. 1.]   \n",
       "4   ...   0.976128        0.188946  0.987124  0.975104 -0.070134    [0. 2.]   \n",
       "5   ...   0.976128        0.188946  1.000000  0.941176 -0.060338    [1. 3.]   \n",
       "6   ...   0.976128        0.188946  0.993651  0.942308 -0.073319    [0. 1.]   \n",
       "7   ...   0.976128        0.188946  1.000000  0.947368 -0.063535    [0. 0.]   \n",
       "8   ...   0.976128        0.188946       NaN  0.947368 -0.123173    [1. 0.]   \n",
       "9   ...   0.976128        0.188946  1.000000  0.882353 -0.033220    [0. 3.]   \n",
       "10  ...   0.976128        0.188946  0.971566  0.904512 -0.039168  [ 1. nan]   \n",
       "11  ...   0.976128        0.188946  0.991885  0.962401 -0.054476  [ 0. nan]   \n",
       "12  ...   0.976128        0.188946  0.974426  0.919429 -0.041711  [nan  4.]   \n",
       "13  ...   0.976128        0.188946  0.986576  0.966926 -0.061638  [nan  2.]   \n",
       "14  ...   0.976128        0.188946  0.983979  0.899329 -0.042548  [nan  1.]   \n",
       "15  ...   0.976128        0.188946  0.980519  0.921569 -0.051299  [nan  3.]   \n",
       "16  ...   0.976128        0.188946  0.972973  0.947368 -0.093354  [nan  0.]   \n",
       "\n",
       "       n level  prevalence  pred_prevalence  \n",
       "0   2813     2    0.257732         0.185567  \n",
       "1    273     2    0.139194         0.120879  \n",
       "2   1320     2    0.077273         0.039394  \n",
       "3     97     2    0.360825         0.237113  \n",
       "4    241     2    0.033195         0.016598  \n",
       "5     34     2    0.147059         0.088235  \n",
       "6     52     2    0.134615         0.076923  \n",
       "7     19     2    0.052632         0.000000  \n",
       "8     19     2    0.000000         0.052632  \n",
       "9     17     2    0.117647         0.000000  \n",
       "10  3236     1    0.248146         0.179852  \n",
       "11  1649     1    0.072771         0.036386  \n",
       "12  4133     1    0.200097         0.138882  \n",
       "13   514     1    0.089494         0.071984  \n",
       "14   149     1    0.281879         0.181208  \n",
       "15    51     1    0.137255         0.058824  \n",
       "16    38     1    0.026316         0.026316  \n",
       "\n",
       "[17 rows x 40 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group settings\n",
    "list_groups = [\n",
    "    '[ 0. nan]',\n",
    "    '[ 1. nan]',\n",
    "    '[nan  0.]',\n",
    "    '[nan  1.]',\n",
    "    '[nan  2.]',\n",
    "    '[nan  3.]',\n",
    "    '[nan  4.]'\n",
    "    \n",
    "    \n",
    "]\n",
    "\n",
    "# the two sensitive groups of interest for all 4 datasets\n",
    "# NB: first item in tuple is sex, second is race\n",
    "# so here sex is considered the sensitive attribute for\n",
    "# Adult and MIMIC and race for COMPAS and LSAC\n",
    "list_groups_dict={}\n",
    "list_groups_dict['adult']=[\n",
    "    '[ 0. nan]',\n",
    "    '[ 1. nan]']\n",
    "list_groups_dict['adult_cleaned']=[\n",
    "    '[ 0. nan]',\n",
    "    '[ 1. nan]']\n",
    "list_groups_dict['mimic_tab_robust']=[\n",
    "     '[ 0. nan]',\n",
    "     '[ 1. nan]']\n",
    "\n",
    "list_groups_dict['lsac']=[\n",
    "    '[nan  0.]',\n",
    "    '[nan  1.]',\n",
    "    '[nan  2.]',\n",
    "    '[nan  3.]',\n",
    "    '[nan  4.]']\n",
    "list_groups_dict['lsac_cat']=[\n",
    "    '[nan  0.]',\n",
    "    '[nan  1.]',\n",
    "    '[nan  2.]',\n",
    "    '[nan  3.]',\n",
    "    '[nan  4.]']\n",
    "\n",
    "list_groups_dict['compas_balanced']=[\n",
    "    '[nan  0.]',\n",
    "    '[nan  1.]']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_alg = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetching hyperparams\n",
    "for path in res_dir.glob('**/*.csv'):\n",
    "    args = json.load((path.parent/'args.json').open('r'))\n",
    "    hparams = [i for i in list(args.keys()) if i not in  ['seed', 'output_dir']]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_gap_row(row, disp='auroc',kind='mean',return_type='str_sum',\n",
    "                    gap_or_not='_gap',\n",
    "                    list_groups=list_groups):\n",
    "    col_names = []\n",
    "    col_mean_names = []\n",
    "    for group in list_groups:\n",
    "        col_names.append(f'{disp}_{group}{gap_or_not}')\n",
    "        col_mean_names.append((f'{disp}_{group}{gap_or_not}',kind))\n",
    "    \n",
    "    if return_type=='str_sum':\n",
    "        max_val_ind = np.nanargmax(row[col_mean_names].values)\n",
    "        val=row[col_names[max_val_ind]]\n",
    "    elif return_type=='n':\n",
    "        max_val_ind = np.nanargmax(row[col_mean_names].values)\n",
    "        val= row[col_mean_names[max_val_ind]]\n",
    "    else:\n",
    "        max_val_ind = np.nanargmax(row[col_names].values)\n",
    "        val= row[col_names[max_val_ind]]\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sens_feature_dict={}\n",
    "sens_feature_dict['adult_cleaned']='1'\n",
    "sens_feature_dict['lsac']='2'\n",
    "sens_feature_dict['mimic_tab_robust']='1'\n",
    "sens_feature_dict['compas_balanced']='2'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# balance sensitive attribute groups by oversampling during training?\n",
    "balance_group_ind = False\n",
    "\n",
    "# balance labels by oversampling during training?\n",
    "# NB: We will always do this for LSAC, see Appendix\n",
    "# in paper\n",
    "balance_labels_ind = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sel=pd.DataFrame(df_raw)\n",
    "df_sel=df_sel[((df_sel.dataset!='lsac')&(df_sel.balance_labels==balance_labels_ind))|\n",
    "              ((df_sel.dataset=='lsac')&(df_sel.balance_labels==True))\n",
    "             ]\n",
    "df_sel=df_sel[df_sel.balance_groups==balance_group_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "LEVEL = 1\n",
    "df=df_sel\n",
    "# df=df[df.seed.isin([1,2,3,4,5])]\n",
    "# df=df[(df.experiment.isin(['lime_balanced_correct_replication']))]\n",
    "\n",
    "res_df = df.query(f'level == {LEVEL}').groupby('output_dir').apply(agg_func)\n",
    "\n",
    "metrics = [i for i in res_df.columns if not i.startswith('worst_group')]\n",
    "out1 = (res_df\n",
    "     .reset_index()\n",
    "     .merge(df[hparams + ['output_dir', 'seed', 'hparam_id']].drop_duplicates()))\n",
    "\n",
    "out2 = (out1.groupby('hparam_id').agg({\n",
    "   i: ('mean', 'std') for i in metrics\n",
    "})\n",
    "       .merge(df[hparams + ['hparam_id']].drop_duplicates().set_index('hparam_id'), left_index = True, right_index = True)\n",
    "       .reset_index())\n",
    "\n",
    "for col in metrics:\n",
    "    out2[col] = out2[(col, 'mean')].apply(lambda x: '{0:.001%}'.format(x)) +' ± ' +  out2[(col, 'std')].apply(lambda x: '{0:.001%}'.format(x))\n",
    "\n",
    "\n",
    "out_all=out2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    True\n",
       "Name: explanation_type, dtype: bool"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_all.explanation_type=='local'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    True\n",
       "Name: blackbox_model, dtype: bool"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_all.blackbox_model.isin(['lr','nn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    adult_cleaned\n",
       "Name: dataset, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_all['dataset']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          hparam_id  (accuracy_all, mean)  \\\n",
      "0  f9c60bd632d6b3136ef80283c5c1c48e              0.924053   \n",
      "\n",
      "   (accuracy_all, std)  (accuracy_min, mean)  (accuracy_min, std)  \\\n",
      "0                  NaN              0.899329                  NaN   \n",
      "\n",
      "   (accuracy_minority, mean)  (accuracy_minority, std)  \\\n",
      "0                   0.947368                       NaN   \n",
      "\n",
      "   (accuracy_majority, mean)  (accuracy_majority, std)  (accuracy_gap, mean)  \\\n",
      "0                   0.919429                       NaN              0.024724   \n",
      "\n",
      "   ...  epsilon_[nan  1.]_gap  epsilon_[nan  2.]_gap  epsilon_[nan  3.]_gap  \\\n",
      "0  ...           -1.2% ± nan%            0.7% ± nan%           -0.4% ± nan%   \n",
      "\n",
      "   epsilon_[nan  4.]_gap  auroc_max_gap  auroc_sens_gap  accuracy_max_gap  \\\n",
      "0           -1.3% ± nan%    0.5% ± nan%     2.0% ± nan%       2.0% ± nan%   \n",
      "\n",
      "   accuracy_sens_gap  epsilon_max_gap  epsilon_sens_gap  \n",
      "0        5.8% ± nan%     -0.0% ± nan%       1.5% ± nan%  \n",
      "\n",
      "[1 rows x 201 columns]\n"
     ]
    }
   ],
   "source": [
    "auroc_gaps=[]\n",
    "acc_gaps=[]\n",
    "for sig in np.sort(out_all.perturb_sigma.unique()):\n",
    "    temp1=out_all[(out_all.explanation_type=='local')&\n",
    "                  (out_all.blackbox_model.isin(['lr','nn']))&\n",
    "                 (out_all.perturb_sigma==sig)]\n",
    "    \n",
    "    # temp1=temp1[temp1.n_features.isin([100])]\n",
    "    # temp1=temp1[(temp1.explanation_model=='shap_blackbox_preprocessed')|\n",
    "    #            (temp1.explanation_model=='lime')|\n",
    "    #            (temp1.explanation_model=='lime_test')|\n",
    "    #             (temp1.explanation_model=='lime_test_new')\n",
    "    #            ]\n",
    "    temp1.loc[temp1.explanation_model=='shap_blackbox_preprocessed','explanation_model']='SHAP'\n",
    "    temp1.loc[temp1.explanation_model=='lime','explanation_model']='LIME'\n",
    "    temp1 = temp1[temp1.dataset.isin(['adult','mimic_tab_robust','lsac','adult_cleaned','compas_balanced'])]\n",
    "    temp1 = temp1[temp1.explanation_model.isin(['LIME','SHAP'])]\n",
    "\n",
    "    for perf_metric in ['auroc','accuracy','epsilon']:\n",
    "        temp1[f'{perf_metric}_max_gap']=temp1.apply(lambda row: get_max_gap_row(row,perf_metric,\n",
    "                                                                       list_groups=list_groups_dict[row['dataset']]), axis=1)\n",
    "        temp1[f'{perf_metric}_sens_gap']=temp1.apply(lambda row: row[f'{perf_metric}_sens{sens_feature_dict[row.dataset]}_gap'],axis=1)\n",
    "        \n",
    "print(temp1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>accuracy_max_gap</th>\n",
       "      <th>accuracy_sens_gap</th>\n",
       "      <th>auroc_all</th>\n",
       "      <th>auroc_sens_gap</th>\n",
       "      <th>epsilon_sens_gap</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <th>blackbox_model</th>\n",
       "      <th>explanation_model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>adult_cleaned</th>\n",
       "      <th>lr</th>\n",
       "      <th>LIME</th>\n",
       "      <td>2.0% ± nan%</td>\n",
       "      <td>5.8% ± nan%</td>\n",
       "      <td>97.6% ± nan%</td>\n",
       "      <td>2.0% ± nan%</td>\n",
       "      <td>1.5% ± nan%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               accuracy_max_gap  \\\n",
       "dataset       blackbox_model explanation_model                    \n",
       "adult_cleaned lr             LIME                   2.0% ± nan%   \n",
       "\n",
       "                                               accuracy_sens_gap  \\\n",
       "dataset       blackbox_model explanation_model                     \n",
       "adult_cleaned lr             LIME                    5.8% ± nan%   \n",
       "\n",
       "                                                   auroc_all auroc_sens_gap  \\\n",
       "dataset       blackbox_model explanation_model                                \n",
       "adult_cleaned lr             LIME               97.6% ± nan%    2.0% ± nan%   \n",
       "\n",
       "                                               epsilon_sens_gap  \n",
       "dataset       blackbox_model explanation_model                   \n",
       "adult_cleaned lr             LIME                   1.5% ± nan%  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_reported_table1=['auroc_all',\n",
    "                 'accuracy_max_gap',\n",
    "                  'auroc_sens_gap',\n",
    "                 'accuracy_sens_gap',\n",
    "                 'epsilon_sens_gap'\n",
    "                      ]\n",
    "# temp1=temp1[temp1.explanation_model=='LIME']\n",
    "pd.pivot_table(data=temp1[['dataset','blackbox_model','explanation_model']+metrics_reported_table1],\n",
    "               values=metrics_reported_table1,   index = ['dataset', 'blackbox_model','explanation_model'], \n",
    "                                                    aggfunc = lambda x: x,\n",
    "                                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llllllll}\n",
      "\\toprule\n",
      "{} &        dataset & blackbox\\_model & explanation\\_model & accuracy\\_max\\_gap & auroc\\_sens\\_gap & accuracy\\_sens\\_gap & epsilon\\_sens\\_gap \\\\\n",
      "\\midrule\n",
      "0 &  adult\\_cleaned &             lr &              LIME &      2.0\\% ± nan\\% &    2.0\\% ± nan\\% &       5.8\\% ± nan\\% &      1.5\\% ± nan\\% \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temp1=temp1[temp1.explanation_model.isin(['LIME'])]\n",
    "print(temp1[['dataset','blackbox_model','explanation_model',\n",
    "#              'auroc_all',\n",
    "#              'auroc_max_gap',\n",
    "             'accuracy_max_gap',\n",
    "             'auroc_sens_gap',\n",
    "             'accuracy_sens_gap',\n",
    "             'epsilon_sens_gap'\n",
    "             ]].sort_values(['dataset','blackbox_model','explanation_model']).to_latex())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
